{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import keras\n",
    "import sys\n",
    "\n",
    "# Import architectures\n",
    "from keras.applications import densenet\n",
    "from keras.applications import xception\n",
    "from keras.applications import resnet_v2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image as im\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, AveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train phase\n",
    "\n",
    "tf.keras.backend.set_learning_phase(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Path to train and test datasets\n",
    "train_dir = \"/home/linnik/Downloads/Face/vggface2_train/\"   \n",
    "test_dir = \"/home/linnik/Downloads/Face/vggface2_test/\"\n",
    "\n",
    "\n",
    "# 2) Target width and height of input images, number of classes, number of train and test images, batch size, epochs\n",
    "img_height, img_width = 250, 250\n",
    "n_classes = len(os.listdir(train_dir))\n",
    "nb_train_samples = sum([len(os.listdir(train_dir + folder)) for folder in os.listdir(train_dir)])\n",
    "nb_test_samples = sum([len(os.listdir(test_dir + folder)) for folder in os.listdir(test_dir)])\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# 3) Compile parametrs\n",
    "loss_ = 'categorical_crossentropy'\n",
    "optimizer_ = 'adam'\n",
    "metrics_ = ['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 5,\n",
    "    width_shift_range = img_width // 5,\n",
    "    height_shift_range = img_height // 5,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    classes = os.listdir(test_dir))\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    classes = os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_test = test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_Xception():\n",
    "    base_model = xception.Xception(include_top = True, \n",
    "                                      weights = None,\n",
    "                                      input_tensor = None,\n",
    "                                      input_shape = (img_height, img_width, 3),\n",
    "                                      pooling = None,\n",
    "                                      classes = n_classes)\n",
    "  \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "      \n",
    "    model = Model(inputs = base_model.input, outputs = base_model.output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model_Xception()\n",
    "model.compile(loss = loss_, optimizer = optimizer_, metrics = metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 8, verbose = 1, min_delta = 1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 4, verbose = 1, min_delta = 1e-4)\n",
    "\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train model\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = nb_test_samples // batch_size,\n",
    "    callbacks = callbacks_list,\n",
    "    steps_per_epoch = nb_train_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phase\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(test_dir, model, dic):\n",
    "    n_classes = len(os.listdir(test_dir))\n",
    "    dic_rev = {v:k for k, v in dic.items()}\n",
    "    \n",
    "    right = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for folder in os.listdir(test_dir):\n",
    "        for img in os.listdir(test_dir + \"/\" + folder):\n",
    "            imag = im.load_img(test_dir + \"/\" + folder + \"/\" + img, target_size = (img_height, img_width))\n",
    "\n",
    "            photo_ar = im.img_to_array(imag)\n",
    "            photo_ar = np.expand_dims(photo_ar, axis = 0)\n",
    "            photo_ar /= 255\n",
    "\n",
    "            ans = np.argmax(model.predict(photo_ar))\n",
    "\n",
    "\n",
    "            if folder == dic_rev[ans]:\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "    \n",
    "    \n",
    "    accuracy = right/(right + wrong)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accuracy = Accuracy(test_dir, model, dic_test)\n",
    "print(\"Accuracy on test set is\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
